{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshu-nakrani/TMLC-Gen-ai-projects/blob/main/Langchain_LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL (LangChain Expression Language) simplifies syntax and it's easy to use for simple chains, but it can get confusing once we add complexity."
      ],
      "metadata": {
        "id": "EgLvqhMgJ7nK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SQW6tyx_J1zR",
        "outputId": "57414248-bae1-41b9-cac5-b1b80c1cebe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.9.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.35 (from langchain)\n",
            "  Downloading langchain_core-0.2.37-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.108-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
            "  Downloading boto3-1.35.10-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx>=0.21.2 (from cohere)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.20.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting botocore<1.36.0,>=1.35.10 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading botocore-1.35.10-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->cohere)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.35->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.23.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.10->boto3<2.0.0,>=1.34.0->cohere) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.6.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.10->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
            "Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.9.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.2/210.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.10-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.37-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.2/396.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.108-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Downloading botocore-1.35.10-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m869.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: types-requests, tenacity, parameterized, orjson, mypy-extensions, marshmallow, jsonpointer, jmespath, httpx-sse, h11, fastavro, typing-inspect, jsonpatch, httpcore, botocore, s3transfer, httpx, dataclasses-json, langsmith, boto3, langchain-core, cohere, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed boto3-1.35.10 botocore-1.35.10 cohere-5.9.0 dataclasses-json-0.6.7 fastavro-1.9.5 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 httpx-sse-0.4.0 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.15 langchain-community-0.2.15 langchain-core-0.2.37 langchain-text-splitters-0.2.2 langsmith-0.1.108 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 parameterized-0.9.0 s3transfer-0.10.2 tenacity-8.5.0 types-requests-2.32.0.20240712 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain cohere langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_community.llms import Cohere\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "Uvd_gYsQKfyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"{question}\")\n",
        "combine_answers_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"Given the question: {question} and the below two answers:\n",
        "Answer 1:\n",
        "{answer1}\n",
        "\n",
        "Answer 2:\n",
        "{answer2}\n",
        "\n",
        "Combine the viewpoints of two answers and form a coherent combined answer.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "gnisCuMWKFJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Cohere(cohere_api_key=userdata.get('COHERE_KEY'),temperature=0.2)\n",
        "model2 = Cohere(cohere_api_key=userdata.get('COHERE_KEY'),temperature=0.2)\n",
        "model3 = Cohere(cohere_api_key=userdata.get('COHERE_KEY'),temperature=0.2)\n",
        "\n",
        "chain1 = prompt | model1 | StrOutputParser()\n",
        "chain2 = prompt | model2 | StrOutputParser()\n",
        "chain3 = combine_answers_prompt | model3 | StrOutputParser()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szXcKXHUKkZB",
        "outputId": "f6db3171-73fa-49b5-b6e7-68d21b89fb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-acc3ed040b95>:1: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import Cohere`.\n",
            "  model1 = Cohere(cohere_api_key=userdata.get('COHERE_KEY'),temperature=0.2)\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
            "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
            "* 'smart_union' has been removed\n",
            "  warnings.warn(message, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What's the best way to stay up to date with latest Large Language Model news? Please keep the answer short and concise, limit to 3 bullet points.\""
      ],
      "metadata": {
        "id": "nqo5m1BlKsyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer1_output = chain1.invoke(question)"
      ],
      "metadata": {
        "id": "nJe5zfEJK0xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer1_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2xPzYSfLCmv",
        "outputId": "c9e0b1fb-45d7-446f-b939-1bcbf60b9b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, developers, and organizations involved in LLM research and innovation regularly share updates on social media platforms like Twitter. By following key accounts and influencers, you can get instant notifications when new insights, papers, or significant developments are shared. \n",
            "\n",
            "2. Subscribe to Research Blogs: Subscribe to influential blogs and websites that offer in-depth coverage of LLM news and advancements. These platforms often provide valuable analysis, expert opinions, and summaries of the latest research papers and developments in the field. \n",
            "\n",
            "3. Subscribe to Press Releases: Keep an eye on tech companies and AI organizations that regularly release press statements regarding their LLM innovations. Joining their email lists or following their official channels can provide insights into commercial LLM applications, new product releases, and impactful deployments. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer2_output = chain2.invoke(question)"
      ],
      "metadata": {
        "id": "sPOp2XVGK1fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer2_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn1Rk6yLLDPM",
        "outputId": "70c633fc-ca47-44b0-81fe-ce4c79b2bfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, companies, and organizations involved in developing and releasing LLMs frequently post about their work on social media platforms such as Twitter, LinkedIn, and blogs. By following these accounts, you can get instant updates about the latest news, discoveries, and insights related to LLMs. \n",
            "\n",
            "2. Subscribe to Newsletter: Subscribe to relevant newsletters from organizations such as Cohere (the parent company of Chatbot), OpenAI, Google AI, and AI-focused media outlets like AI Hub, which provide regular updates and in-depth articles about LLMs and AI advancements. \n",
            "\n",
            "3. AI Podcasts and YouTube Channels: Tune into engaging AI podcasts and YouTube channels that regularly invite experts and researchers to discuss the latest developments in the field of LLMs. These audio and video platforms often offer concise and insightful analyses of the newest advancements and future trajectories in the realm of large language models. \n",
            "\n",
            "These platforms will provide a balanced mix of sources for your information needs on LLM news and developments. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_answer_output = chain3.invoke({\"question\": question, \"answer1\": answer1_output, \"answer2\": answer2_output})"
      ],
      "metadata": {
        "id": "Io0l0Dm9K2lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_answer_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Otu5bsqLJP4",
        "outputId": "33236ac3-764a-4931-ce13-c014298ef0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, companies, and organizations involved in developing and releasing LLMs frequently post about their work on social media platforms such as Twitter, LinkedIn, and blogs. By following these accounts, you can get instant updates about the latest news, discoveries, and insights related to LLMs. \n",
            "\n",
            "2. Subscribe to Newsletter: Subscribe to relevant newsletters from organizations such as Cohere (the parent company of Chatbot), OpenAI, Google AI, and AI-focused media outlets like AI Hub, which provide regular updates and in-depth articles about LLMs and AI advancements. \n",
            "\n",
            "3. Explore Multiple Sources: Subscribe to research blogs and tune into AI podcasts and YouTube channels that cover the latest developments in the field of LLMs. Leveraging a combination of sources will provide a holistic understanding of this rapidly evolving domain. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_chain = {\n",
        "    \"question\": RunnablePassthrough(),\n",
        "    \"answer1\": chain1,\n",
        "    \"answer2\": chain2,\n",
        "} | chain3\n",
        "\n",
        "combined_answer = combined_chain.invoke(question)"
      ],
      "metadata": {
        "id": "AgRYc8yKK9o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfqEHoZXLUjB",
        "outputId": "23ae6ab2-7900-4e5f-fae8-e928042f7a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, developers, and organizations involved in LLM research and innovation regularly share updates on social media platforms like Twitter. By following key accounts and influencers, you can stay informed about the latest advancements, papers, and discussions surrounding LLMs. \n",
            "\n",
            "2. Subscribe to Research Blogs: Subscribe to influential blogs and websites that offer in-depth coverage of LLM news and developments. These platforms often cover a range of topics, including the latest research papers, technical innovations, and industry use cases. \n",
            "\n",
            "3. Attend Conferences and Events: Attending conferences and events related to AI and natural language processing can provide valuable insights into the world of large language models. These events often feature keynote speeches, panel discussions, and networking opportunities to stay abreast of the newest industry advancements. \n",
            "\n",
            "By utilizing these methods, you can stay up-to-date on the latest Large Language Model news and developments. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_chain = (\n",
        "    {\"question\": RunnablePassthrough()}\n",
        "    | RunnablePassthrough.assign(answer1=chain1)\n",
        "    | RunnablePassthrough.assign(answer2=chain2)\n",
        "    | chain3\n",
        ")"
      ],
      "metadata": {
        "id": "YbEWm2qcK-46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X3jKd0KLWIo",
        "outputId": "3c840433-9912-4023-a48a-92a3e0690be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first={\n",
            "  question: RunnablePassthrough()\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  answer1: ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])\n",
            "           | Cohere(client=<cohere.client.Client object at 0x7ba8dfd4fa60>, async_client=<cohere.client.AsyncClient object at 0x7ba8dd802830>, temperature=0.2, cohere_api_key=SecretStr('**********'))\n",
            "           | StrOutputParser()\n",
            "}), RunnableAssign(mapper={\n",
            "  answer2: ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])\n",
            "           | Cohere(client=<cohere.client.Client object at 0x7ba8dd8034f0>, async_client=<cohere.client.AsyncClient object at 0x7ba8dd803e20>, temperature=0.2, cohere_api_key=SecretStr('**********'))\n",
            "           | StrOutputParser()\n",
            "}), ChatPromptTemplate(input_variables=['answer1', 'answer2', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer1', 'answer2', 'question'], template='Given the question: {question} and the below two answers:\\nAnswer 1:\\n{answer1}\\n\\nAnswer 2:\\n{answer2}\\n\\nCombine the viewpoints of two answers and form a coherent combined answer.\\n'))]), Cohere(client=<cohere.client.Client object at 0x7ba8dd8248b0>, async_client=<cohere.client.AsyncClient object at 0x7ba8dd8251e0>, temperature=0.2, cohere_api_key=SecretStr('**********'))] last=StrOutputParser()\n"
          ]
        }
      ]
    }
  ]
}