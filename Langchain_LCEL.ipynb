{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshu-nakrani/TMLC-Gen-ai-projects/blob/main/Langchain_LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL (LangChain Expression Language) simplifies syntax and it's easy to use for simple chains, but it can get confusing once we add complexity."
      ],
      "metadata": {
        "id": "EgLvqhMgJ7nK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SQW6tyx_J1zR",
        "outputId": "22f0b6bd-17e2-4435-94da-374d040ac79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.13.4-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.21.0)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n",
            "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.13.4-py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: types-requests, python-dotenv, parameterized, mypy-extensions, marshmallow, httpx-sse, fastavro, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, cohere, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed cohere-5.13.4 dataclasses-json-0.6.7 fastavro-1.10.0 httpx-sse-0.4.0 langchain-0.3.13 langchain-community-0.3.13 langchain-core-0.3.28 marshmallow-3.23.2 mypy-extensions-1.0.0 parameterized-0.9.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 types-requests-2.32.0.20241016 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain cohere langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_community.llms import Cohere\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "Uvd_gYsQKfyB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"{question}\")\n",
        "combine_answers_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"Given the question: {question} and the below two answers:\n",
        "Answer 1:\n",
        "{answer1}\n",
        "\n",
        "Answer 2:\n",
        "{answer2}\n",
        "\n",
        "Combine the viewpoints of two answers and form a coherent combined answer.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "gnisCuMWKFJq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Cohere(cohere_api_key=userdata.get('COHERE_KEY'),temperature=0.2)\n",
        "model2 = Cohere(cohere_api_key=userdata.get('COHERE_KEY'),temperature=0.2)\n",
        "model3 = Cohere(cohere_api_key=userdata.get('COHERE_KEY'),temperature=0.2)\n",
        "\n",
        "chain1 = prompt | model1 | StrOutputParser()\n",
        "chain2 = prompt | model2 | StrOutputParser()\n",
        "chain3 = combine_answers_prompt | model3 | StrOutputParser()"
      ],
      "metadata": {
        "id": "szXcKXHUKkZB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What's the best way to stay up to date with latest Large Language Model news? Please keep the answer short and concise, limit to 3 bullet points.\""
      ],
      "metadata": {
        "id": "nqo5m1BlKsyY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer1_output = chain1.invoke(question)"
      ],
      "metadata": {
        "id": "nJe5zfEJK0xL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer1_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2xPzYSfLCmv",
        "outputId": "e8f58b82-8d34-4d87-cf7e-7ed3105d8118"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, developers, and organizations involved in LLM research and innovation regularly share updates on social media platforms like Twitter. By following key figures and organizations involved in LLM R&D, you can stay informed about the latest advancements, publications, and events in the field. \n",
            "\n",
            "2. Subscribe to Newsletters and Blogs: Many companies and research institutions provide newsletters and blog subscriptions that deliver curated content related to LLMs and AI. Subscribing to these resources ensures that you receive timely updates directly in your inbox. \n",
            "\n",
            "3. Participate in Online Communities: Joining online communities and forums dedicated to discussing AI and LLM topics can provide a continuous stream of information and insights. Reddit and Discord servers focused on AI and LLM discussions can offer both news and in-depth analysis and conversations about recent developments. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer2_output = chain2.invoke(question)"
      ],
      "metadata": {
        "id": "sPOp2XVGK1fA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer2_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn1Rk6yLLDPM",
        "outputId": "8d5c4b38-8aef-4d44-fc51-bcb118146abc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, developers, and organizations involved in LLM research and development regularly share updates and news on social media platforms like Twitter. By following key figures and organizations involved in LLM R&D, you can stay informed on the most recent developments in the field. \n",
            "\n",
            "2. Subscribe to Newsletters and Blogs: Many companies and research institutions provide newsletters and blog platforms that offer detailed updates regarding their ongoing projects. Subscribing to these sources can provide you with tailored information about LLM news and advancements. \n",
            "\n",
            "3. Participate in Online Communities: Joining online forums, subreddits, or Discord servers related to LLM's can connect you to a community of enthusiasts and experts. These platforms can be excellent for sharing information, discussing the latest news, and learning about ongoing developments within the field. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_answer_output = chain3.invoke({\"question\": question, \"answer1\": answer1_output, \"answer2\": answer2_output})"
      ],
      "metadata": {
        "id": "Io0l0Dm9K2lg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_answer_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Otu5bsqLJP4",
        "outputId": "d396915d-ec55-4f34-c572-bd548c01e03a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, developers, and organizations involved in LLM research and development regularly share updates and news on social media platforms like Twitter. By following key figures and organizations involved in LLM R&D, you can stay informed on the most recent developments in the field. \n",
            "\n",
            "2. Subscribe to Newsletters and Blogs: Many companies and research institutions provide newsletters and blog platforms that offer detailed updates regarding their ongoing projects. Subscribing to these sources can provide you with tailored information about LLM news and advancements. \n",
            "\n",
            "3. Participate in Online Communities: Joining online forums, subreddits, or Discord servers related to LLM's can connect you to a community of enthusiasts and experts. These platforms can be excellent for sharing information, discussing the latest news, and learning about ongoing developments within the field. \n",
            "\n",
            "By combining these methods, you can stay informed and connected with the latest advancements in Large Language Models. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_chain = {\n",
        "    \"question\": RunnablePassthrough(),\n",
        "    \"answer1\": chain1,\n",
        "    \"answer2\": chain2,\n",
        "} | chain3\n",
        "\n",
        "combined_answer = combined_chain.invoke(question)"
      ],
      "metadata": {
        "id": "AgRYc8yKK9o6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfqEHoZXLUjB",
        "outputId": "a6849155-b809-4fd2-d411-2e0af394e258"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, developers, and organizations involved in LLM research and innovation regularly share updates on social media platforms like Twitter. By following key accounts and hashtags related to LLM's, you can stay informed about the latest news, articles, and insights from experts in the field. \n",
            "\n",
            "2. Subscribe to Specialized Blogs and Newsletter: Several organizations, including research labs and tech companies that develop LLMs, maintain blogs and newsletters focused on AI, language models, and their advancements. Subscribing to these blogs and newsletters ensures that you receive curated updates directly in your inbox or through regular visits to relevant websites. They provide insights, articles, and opinions from industry experts, many of whom are at the forefront of LLM development. \n",
            "\n",
            "3. Participate in Online Communities: Joining online forums, message boards, and communities focused on AI and LLM's can provide opportunities to engage in discussions, ask questions, and stay informed about the latest news and insights. Online platforms like Reddit and Discord have dedicated channels and servers that actively share and update information about LLM's. Participating in these communities can offer real-time updates, diverse perspectives,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_chain = (\n",
        "    {\"question\": RunnablePassthrough()}\n",
        "    | RunnablePassthrough.assign(answer1=chain1)\n",
        "    | RunnablePassthrough.assign(answer2=chain2)\n",
        "    | chain3\n",
        ")"
      ],
      "metadata": {
        "id": "YbEWm2qcK-46"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_answer = combined_chain.invoke(question)"
      ],
      "metadata": {
        "id": "AnD8jPvOTwzs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X3jKd0KLWIo",
        "outputId": "142fcc71-c5b7-47b9-ecce-d34613043447"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here are three ways to stay informed about the latest news and updates regarding Large Language Models: \n",
            "\n",
            "1. Follow Social Media Accounts: Many researchers, developers, and organizations involved in LLM research and innovation regularly post updates on social media platforms like Twitter. By following key figures and organizations involved in LLM R&D, you can stay informed about the latest advancements, publications, and events in the field. \n",
            "\n",
            "2. Subscribe to Research Blogs: Many academic institutions and research organizations involved in LLM research maintain public blogs or newsletters. Subscribing to these blogs will keep you informed on a regular basis. You will be among the first to know about important breakthroughs, conference presentations, and opportunities to participate in the field. \n",
            "\n",
            "3. Attend Webinars and Virtual Conferences: Given the rapid advancement of LLM technology, virtual conferences and webinars have become increasingly popular. Attending these events can provide valuable insights and put you in direct contact with leading researchers and developers, allowing you to deepen your understanding of the field and engage with experts. \n",
            "\n",
            "Remember, staying informed requires dedicated effort and regular engagement with relevant sources. These three options should serve as a good starting point for staying current with Large Language Model news and advancements. \n",
            "Here is a bonus tip: \n"
          ]
        }
      ]
    }
  ]
}